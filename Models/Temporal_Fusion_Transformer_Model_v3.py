# Auto-generated from notebook by scripts/convert_notebooks.py
# Do not edit this file directly; edit the corresponding .ipynb instead.

#!/usr/bin/env python
# coding: utf-8

# # 72-Hour Renewable Energy Forecast (Temporal Fusion Transformer) - V3 Season-aware Model
# 
# ## Modifications for V3:
# 
# This notebook enhances the V2 Temporal Fusion Transformer (TFT) model with several key improvements aimed at boosting predictive accuracy and robustness:
# 
# 1.  **Huber Loss Function**: The `Mean Absolute Error` loss function has been replaced with the `Huber` loss. This provides a more robust error metric that is less sensitive to outliers, which is beneficial for noisy time series data.
# 
# 2.  **L2 Regularization**: To prevent overfitting, L2 regularization (`kernel_regularizer`) has been added to all `Dense`, `LSTM`, and `MultiHeadAttention` layers. This encourages the model to learn smaller, more generalizable weights.
# 
# 3.  **Increased Model Capacity**: The model's capacity has been significantly increased to capture more complex patterns in the data. The internal model dimension (`d_model`) is increased from 64 to 128, and the number of attention heads is increased from 2 to 4.
# 
# 4.  **Deeper MLP Head**: The final MLP head has been made deeper (from a single `Dense(128)` layer to `Dense(256)` -> `Dense(128)`). This allows for more sophisticated feature processing before the final output, potentially improving forecast accuracy.

# In[ ]:


import pandas as pd


import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Add, GlobalAveragePooling1D, Multiply, LSTM
from tensorflow.keras.callbacks import ReduceLROnPlateau
from datetime import datetime, timedelta
import os
from sklearn.metrics import r2_score
from scripts.season import resolve_season, months_for, data_path
SEASON = resolve_season(default='Winter').capitalize()
MONTHS = months_for(SEASON.lower())

print(f"TensorFlow Version: {tf.__version__}")


# In[ ]:


# --- Data Parameters ---
LOOK_BACK = 72          # Use past 72 hours (3 days) of data to predict
FORECAST_HORIZON = 72   # Predict next 72 hours
N_FEATURES = 1          # We are using only 'renewable_percentage' as the input feature
COUNTRY_CODE = (os.environ.get("COUNTRY_CODE") or os.environ.get("BIONET_COUNTRY_CODE") or "DE").upper()
YEARS_HISTORY = 5       # Set history to 5 years

# --- Seasonal Parameters (Winter) ---
DATA_FILENAME = str(data_path(f"energy_data_{COUNTRY_CODE}_{YEARS_HISTORY}years_{SEASON.lower()}.csv"))


# In[ ]:


def create_sequences(data_values_scaled, look_back, forecast_horizon):
    """Creates sequences of X (input) and y (target) for time series forecasting."""
    X_list, y_list = [], []
    if len(data_values_scaled) < look_back + forecast_horizon:
        print(f"Not enough data to create sequences. Data length: {len(data_values_scaled)}, "
              f"Required: {look_back + forecast_horizon}")
        return np.array(X_list), np.array(y_list)
        
    for i in range(len(data_values_scaled) - look_back - forecast_horizon + 1):
        X_list.append(data_values_scaled[i:(i + look_back)])
        y_list.append(data_values_scaled[(i + look_back):(i + look_back + forecast_horizon)])
    return np.array(X_list), np.array(y_list)


# In[ ]:


# --- Load and filter data from the seasonal CSV file ---
print(f"Loading data from file: {DATA_FILENAME}")
try:
    cached_data = pd.read_csv(DATA_FILENAME, index_col=0, parse_dates=True)
    # Filter the loaded data to ensure it only contains selected season months
    seasonal_data = cached_data[cached_data.index.month.isin(MONTHS)]
    renewable_series_data = seasonal_data.squeeze()
    print(f"{SEASON} data loaded and filtered successfully.")
except FileNotFoundError:
    print(f"CRITICAL: Data file not found at '{os.path.abspath(DATA_FILENAME)}'.")
    print(f"Please ensure the {SEASON.lower()} CSV file exists.")
    renewable_series_data = None

# --- The rest of the cell proceeds from here ---
X_train, y_train = np.array([]), np.array([])
X_valid, y_valid = np.array([]), np.array([])
X_test, y_test = np.array([]), np.array([])
scaler = MinMaxScaler(feature_range=(0, 1)) # Initialize scaler here for later use

if renewable_series_data is not None and not renewable_series_data.empty:
    print(f"\nOriginal data points loaded: {len(renewable_series_data)}")
    # Scale the data
    data_for_scaling = renewable_series_data.values.reshape(-1, 1)
    scaled_data_values = scaler.fit_transform(data_for_scaling).flatten()

    # Create sequences
    X_seq, y_seq = create_sequences(scaled_data_values, LOOK_BACK, FORECAST_HORIZON)

    if X_seq.shape[0] > 0:
        X_seq = X_seq.reshape((X_seq.shape[0], X_seq.shape[1], N_FEATURES))

        # Chronological split for time series
        train_size_idx = int(len(X_seq) * 0.70)
        valid_size_idx = int(len(X_seq) * 0.15)

        X_train, y_train = X_seq[:train_size_idx], y_seq[:train_size_idx]
        X_valid, y_valid = X_seq[train_size_idx : train_size_idx + valid_size_idx], y_seq[train_size_idx : train_size_idx + valid_size_idx]
        X_test, y_test = X_seq[train_size_idx + valid_size_idx:], y_seq[train_size_idx + valid_size_idx:]
else:
    print("CRITICAL: No data loaded or data is empty. Cannot proceed with model training.")

print(f"\nData Split:")
print(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
print(f"X_valid shape: {X_valid.shape}, y_valid shape: {y_valid.shape}")
print(f"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}")


# In[ ]:


# V2: Corrected Gated Linear Unit
def gated_linear_unit(inputs, l2_reg):
    x_sigmoid = Dense(inputs.shape[-1], activation='sigmoid', kernel_regularizer=l2_reg)(inputs)
    x_linear = Dense(inputs.shape[-1], activation='linear', kernel_regularizer=l2_reg)(inputs)
    return Multiply()([x_sigmoid, x_linear])

def gated_residual_network(inputs, d_model, dropout_rate, l2_reg):
    x = Dense(d_model, activation='elu', kernel_regularizer=l2_reg)(inputs)
    x = Dense(d_model, kernel_regularizer=l2_reg)(x)
    x = Dropout(dropout_rate)(x)
    gated_x = gated_linear_unit(x, l2_reg)
    return Add()([inputs, gated_x])

def build_tft_model(input_shape, forecast_horizon, d_model=128, num_heads=4, d_ff=256, dropout=0.1):
    l2_reg = tf.keras.regularizers.l2(0.001)
    inputs = Input(shape=input_shape)
    
    # Variable Selection Network (simplified for univariate)
    vsn_out = Dense(d_model, kernel_regularizer=l2_reg)(inputs)
    
    # LSTM Encoder
    lstm_out = LSTM(d_model, return_sequences=True, kernel_regularizer=l2_reg)(vsn_out)
    lstm_out = Add()([lstm_out, vsn_out]) # Add residual connection
    lstm_out = LayerNormalization()(lstm_out)
    
    # Gated Residual Network
    grn_out = gated_residual_network(lstm_out, d_model, dropout, l2_reg)
    
    # Self-Attention
    attention_out = MultiHeadAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout, kernel_regularizer=l2_reg)(grn_out, grn_out)
    attention_out = LayerNormalization(epsilon=1e-6)(Add()([attention_out, grn_out]))
    
    # Another Gated Residual Network
    grn_out_2 = gated_residual_network(attention_out, d_model, dropout, l2_reg)
    
    # Output Layer
    x = GlobalAveragePooling1D()(grn_out_2)
    x = Dense(256, activation='relu', kernel_regularizer=l2_reg)(x)
    x = Dropout(0.3)(x)
    x = Dense(128, activation='relu', kernel_regularizer=l2_reg)(x)
    x = Dropout(0.3)(x)
    outputs = Dense(forecast_horizon)(x)
    
    model = Model(inputs=inputs, outputs=outputs)
    model.summary(line_length=120)
    return model

# Build the model
solar_model = None
if X_train.shape[0] > 0:
    solar_model = build_tft_model(
        input_shape=(LOOK_BACK, N_FEATURES),
        forecast_horizon=FORECAST_HORIZON
    )
else:
    print("Skipping model building as no training data is available.")


# In[ ]:


history = None
if solar_model and X_train.shape[0] > 0:
    print("\n--- Starting Model Training ---")
    
    # V3: Use Huber loss
    loss = tf.keras.losses.Huber()
    solar_model.compile(optimizer='adam', loss=loss, metrics=['mae'])
    
    early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss', 
        patience=30,
        restore_best_weights=True
    )
    
    # V2 Improvement: Add learning rate scheduler
    lr_scheduler = ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=5,
        min_lr=1e-6,
        verbose=1
    )
    
    history = solar_model.fit(X_train, y_train,
                              validation_data=(X_valid, y_valid),
                              epochs=500,
                              batch_size=32,
                              verbose=1,
                              callbacks=[early_stopping, lr_scheduler])

    # --- Plotting and Evaluation ---
    from sklearn.metrics import mean_absolute_error, mean_squared_error

    # Plotting Training Loss
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title(f'Model Loss During Training ({SEASON}) - TFT V3')
    plt.ylabel('Loss (Huber)')
    plt.xlabel('Epoch')
    plt.legend(loc='upper right')
    plt.grid(True)
    plt.savefig(f"training_loss_plot_{SEASON.lower()}_tft_v3.png")

    # Final Model Evaluation
    if X_test.shape[0] > 0:
        print("\n--- Evaluating Model on Test Set ---")
        y_pred_scaled = solar_model.predict(X_test)
        
        y_test_reshaped = y_test.reshape(-1, 1)
        y_pred_reshaped = y_pred_scaled.reshape(-1, 1)

        y_test_inversed = scaler.inverse_transform(y_test_reshaped)
        y_pred_inversed = scaler.inverse_transform(y_pred_reshaped)

        mae_overall = mean_absolute_error(y_test_inversed, y_pred_inversed)
        mse_overall = mean_squared_error(y_test_inversed, y_pred_inversed)
        rmse_overall = np.sqrt(mse_overall)
        r2_overall = r2_score(y_test_inversed, y_pred_inversed)

        print(f"\nOverall Test Set Metrics (on inverse-transformed data):")
        print(f"  Mean Absolute Error (MAE): {mae_overall:.4f}")
        print(f"  Mean Squared Error (MSE):  {mse_overall:.4f}")
        print(f"  Root Mean Squared Error (RMSE): {rmse_overall:.4f}")
        print(f"  R-squared (R²): {r2_overall:.4f}")

        # Make a Sample Prediction and Plot
        num_plots = min(3, len(X_test))
        if num_plots > 0:
            plt.figure(figsize=(15, 5 * num_plots))
            for i in range(num_plots):
                sample_index = np.random.randint(0, len(X_test))
                
                historical_input_inversed = scaler.inverse_transform(X_test[sample_index])
                y_true_inversed_plot = scaler.inverse_transform(y_test[sample_index].reshape(-1, 1))
                y_pred_inversed_plot = scaler.inverse_transform(y_pred_scaled[sample_index].reshape(-1, 1))

                time_axis_input = np.arange(-LOOK_BACK, 0)
                time_axis_output = np.arange(0, FORECAST_HORIZON)
                
                plt.subplot(num_plots, 1, i + 1)
                plt.plot(time_axis_input, historical_input_inversed.flatten(), label='Historical Input', marker='o', linestyle=':', color='gray', alpha=0.7)
                plt.plot(time_axis_output, y_true_inversed_plot, label='Actual Future', marker='.', color='blue')
                plt.plot(time_axis_output, y_pred_inversed_plot, label='Predicted Future', marker='x', linestyle='--', color='red')
                plt.title(f'{FORECAST_HORIZON}-Hour Forecast ({SEASON} - Test Sample {sample_index}) - V3')
                plt.xlabel('Time (Hours into the future)')
                plt.ylabel('Renewable Percentage (%)')
                plt.axvline(x=0, color='k', linestyle='--', linewidth=0.8, label='Forecast Start (T=0)')
                plt.legend()
                plt.grid(True)
            plt.tight_layout()
            plt.savefig(f"forecast_examples_{SEASON.lower()}_tft_v3.png")
            
        # --- BENCHMARKING REPORT ---
        print("\n\n--- BENCHMARKING REPORT (V3) ---")
        total_params = solar_model.count_params()
        model_size_mb = total_params * 4 / (1024**2)
        print(f"{'Model Name:':<25} Temporal Fusion Transformer ({SEASON} V3)")
        print(f"{'Key Features / Inputs:':<25} Renewable % (Univariate)")
        print("-" * 40)
        print(f"{'MAE:':<25} {mae_overall:.4f}")
        print(f"{'RMSE:':<25} {rmse_overall:.4f}")
        print(f"{'R²:':<25} {r2_overall:.4f}")
        print(f"{'Model Size (MB):':<25} {model_size_mb:.2f} MB")
        print(f"{'# of Params (M):':<25} {total_params / 1e6:.2f} M")
        print("-" * 40)
    else:
        print("No test data to evaluate or plot.")
else:
    print("CRITICAL: Not enough data to train the model.")